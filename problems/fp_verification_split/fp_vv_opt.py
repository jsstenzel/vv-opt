import sys
import os
import scipy.stats
import math
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import csv
import dill

sys.path.append('../..')
#focal plane
from problems.fp_verification_split.fp_problem import *
#analysis
from uq.uncertainty_propagation import *
#from uq.sensitivity_analysis import *

################################
#Useful definitions
################################

def proposal_fn_gamma(theta_curr, proposal_width):
	theta_prop = [0] * len(theta_curr)
	for i,_ in enumerate(theta_prop):
		#proposal dists are gammas, to match
		mean = abs(theta_curr[i])
		stddev = proposal_width
		variance = [w**2 for w in stddev]
		alpha = mean**2 / variance
		beta = mean / variance
		theta_prop[i] = scipy.stats.gamma.rvs(size=1, a=alpha, scale=1.0/beta)[0]
	return theta_prop
	
def proposal_fn_norm(theta_curr, proposal_width):
	theta_prop = [0] * len(theta_curr)
	for i,_ in enumerate(theta_prop):
		#proposal dists are gammas, to match
		mean = abs(theta_curr[i])
		stddev = proposal_width[i]
		theta_prop[i] = scipy.stats.norm.rvs(size=1, loc=mean, scale=stddev)[0]
	return theta_prop

req = 4.38 #max noise

theta_nominal = [1.1, 2.5, .001]
QoI_nominal = fp.H(theta_nominal)

d_historical = [
				20,   #t_gain
				30,   #I_gain
				1,	#n_meas_rn
				8,	#d_num
				9600, #d_max
				2	 #d_pow   #approx
			   ]
			   
d_best = [
				600,   #t_gain
				100,   #I_gain
				50,	#n_meas_rn
				100,	#d_num
				12000, #d_max
				3	 #d_pow   #approx
		]
			   
d_worst = [
				1,   #t_gain
				1,   #I_gain
				1,	#n_meas_rn
				2,	#d_num
				1, #d_max
				0.1	 #d_pow   #approx
		]
		
"""
[7.77237510e+00	15	33	14		8.11605996e+03	7.06310387e-01]
[1.00000025e-01	1	1	2		1.00000042e+00	7.06371257e-01]
[6.35403517e+00	15	2	14		6.44717674e+02	7.76511282e-01]
[7.77237510e+00	15	2	14		7.95632020e+03	7.05273965e-01]
[6.36736687e+00	15	2	14		1.52676320e+02	7.05259828e-01]
[1.00000545e-01	1	3	2		2.65068990e+00	8.99019278e-01]
[1.00000080e-01	1	1	2		1.48736520e+00	7.65832613e-01]
[1.00000545e-01	1	3	2		1.91876114e+00	9.27046263e-01]
[6.35403517e+00	15	2	13		1.09104547e+01	7.76511282e-01]
[1.00000228e-01	1	2	2		1.66777101e+00	8.16472929e-01]
[1.00000057e-01	1	1	2		1.06501321e+00	7.65137827e-01]
[1.00000056e-01	1	1	2		6.80956735e+00	7.65832613e-01]]
"""
		
y_nominal = fp._internal_G(dict(zip(fp.theta_names, theta_nominal)), dict(zip(fp.d_names, d_historical)), dict(zip(fp.x_names, fp.x_default)))
#print(y_nominal)

################################
#Analysis functions
################################

def fp_vv_nominal():
	print("QoI requirement:", req)
	print("Nominal QoI:", QoI_nominal)


###uncertainty analysis
def fp_vv_UP_QoI(req):
	#uncertainty propagation of HLVA
	uq_thetas = fp.prior_rvs(10000)
	Qs = [fp.H(theta) for theta in uq_thetas]
	uncertainty_prop_plot([theta[0] for theta in uq_thetas], xlab="Gain [ADU/e-]")
	uncertainty_prop_plot([theta[1] for theta in uq_thetas], xlab="Read noise [e-]")
	uncertainty_prop_plot([theta[2] for theta in uq_thetas], xlab="Dark current [e-/s]")
	uncertainty_prop_plot(Qs, xlab="QoI: Avg. Noise [e-]", vline=[req])

	#prob of meeting req along priors:
	count_meetreq = 0
	for Q in Qs:
		if Q <= req:
			count_meetreq += 1
	prob_meetreq = count_meetreq / len(Qs)
	print("Probability of meeting requirement given priors:", prob_meetreq)

"""
#sensitivity analysis of HLVA
def fp_vv_SA_QoI():
	#it'll be straightforward to see the dependence of QoI on theta
	Si = sobol_saltelli(fp.H, 
						2**5, #SALib wants powers of 2 for convergence
						var_names=fp.theta_names, 
						var_dists=[prior[0] for prior in fp.priors], 
						var_bounds=[prior[1] for prior in fp.priors], 
						conf = 0.95, doSijCalc=False, doPlot=True, doPrint=True)
"""

#Uncertainty analysis of the experiment models
def fp_vv_UP_exp(dd, savefig=False):
	print("Likelihood distribution for nominal historical case:",flush=True)
	tt = fp.prior_rvs(1); print(tt)
	ysample_nominal = [fp.eta(tt, dd) for _ in range(10000)]
	uncertainty_prop_plots(ysample_nominal, xlabs=["Y0","Y1","Y2"], saveFig='UP_exp_nominal' if savefig else '')
	#kde_plot(likelihood, ysample_nominal, plotStyle='together') #needs fixing?
	
	#Also plot the y's generated by the joint distribution p(y|theta,d)p(theta)
	print("Experiments simulated from the joint distribution:",flush=True)
	uq_thetas = fp.prior_rvs(10000)
	uq_ys = [fp.eta(theta, dd) for theta in uq_thetas]
	uncertainty_prop_plot([y[0] for y in uq_ys], xlab="Y0 (joint distribution)", c='orchid', saveFig='UP_joint_y0' if savefig else '')
	uncertainty_prop_plot([y[1] for y in uq_ys], xlab="Y1 (joint distribution)", c='orchid', saveFig='UP_joint_y1.png' if savefig else '')
	uncertainty_prop_plot([y[2] for y in uq_ys], xlab="Y2 (joint distribution)", c='orchid', saveFig='UP_joint_y2' if savefig else '')

def fp_vv_plot_likelihood(dd):
	uq_thetas = fp.prior_rvs(10000)
	uq_ys = [fp.eta(theta, dd) for theta in uq_thetas]
	y_likelihoods = [fp.eta_likelihood(y, uq_thetas[i], dd) for i,y in enumerate(uq_ys)]
	
	y0_probs = [list(i) for i in zip([y[0] for y in uq_ys], y_likelihoods)]
	y1_probs = [list(i) for i in zip([y[1] for y in uq_ys], y_likelihoods)]
	y2_probs = [list(i) for i in zip([y[2] for y in uq_ys], y_likelihoods)]
	y0_probs.sort(key=lambda x: x[0])
	y1_probs.sort(key=lambda x: x[0])
	y2_probs.sort(key=lambda x: x[0])
	
	plt.plot([elem[0] for elem in y0_probs], [elem[1] for elem in y0_probs])
	plt.show()
	plt.plot([elem[0] for elem in y1_probs], [elem[1] for elem in y1_probs])
	plt.show()
	plt.plot([elem[0] for elem in y2_probs], [elem[1] for elem in y2_probs])
	plt.show()
	
def uncertainty_mc():
	util_samples = []
	for ii in range(1000):
		print(ii, flush=True)
		util = U_varH_gbi(d_historical, fp, n_mc=5*10**3, n_gmm=10**3, ncomp=5, doPrint=False)
		util_samples.append(util)
		
	uncertainty_prop_plot(util_samples, c='purple', xlab="utility for d=d_hist")
	print(statistics.variance(util_samples))

if __name__ == '__main__':  
	#fp_vv_nominal()
	
	#fp_vv_UP_QoI(4.38)
	
	#fp_vv_SA_QoI()
	
	#fp_vv_UP_exp(d_historical)
	#fp_vv_UP_exp(d_best, False)
	#fp_vv_UP_exp(d_worst, False)
	
	fp_vv_plot_likelihood(d_historical)

	
