import sys
import os
import scipy.stats
import math
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import csv
import dill

sys.path.append('../..')
#focal plane
from problems.simple_mass.simple_mass_problem import *
#analysis
from obed.obed_multivar import *
from obed.obed_gbi import *
from obed.pdf_estimation import *
from uq.uncertainty_propagation import *
from uq.sensitivity_analysis import *
from opt.ngsa import *

################################
#Useful definitions
################################

################################
#Analysis functions
################################

def vv_nominal(problem, req, theta_nominal, y_nominal):
	print("QoI requirement:", req)
	QoI_nominal = problem.H(theta_nominal)
	print("Given the nominal theta:", theta_nominal)
	print("Nominal y:", y_nominal)
	print("Nominal QoI:", QoI_nominal)


###uncertainty analysis
def vv_UP_QoI(problem, req, n=10**4):
	#uncertainty propagation of HLVA
	uq_thetas = problem.prior_rvs(n)
	Qs = [problem.H(theta) for theta in uq_thetas]
	#uncertainty_prop_plot([theta[0] for theta in uq_thetas], xlab="How to plot this...")
	uncertainty_prop_plot(Qs, xlab="QoI: Total Mass", vline=[req])

	#prob of meeting req along priors:
	count_meetreq = 0
	for Q in Qs:
		if Q <= req:
			count_meetreq += 1
	prob_meetreq = count_meetreq / len(Qs)
	print("Probability of meeting requirement given priors:", prob_meetreq)

#sensitivity analysis of HLVA
def vv_SA_QoI(problem, p=5):
	#it'll be straightforward to see the dependence of QoI on theta
	Si = sobol_saltelli(problem.H, 
						2**p, #SALib wants powers of 2 for convergence
						var_names=problem.theta_names, 
						var_dists=[prior[0] for prior in problem.priors], 
						var_bounds=[prior[1] for prior in problem.priors], 
						conf = 0.95, doSijCalc=False, doPlot=True, doPrint=True)

#Uncertainty analysis of the experiment models
def vv_UP_exp(problem, dd, theta_nominal, n=10**4, savefig=False):
	print("Likelihood distribution for nominal historical case:",flush=True)
	#tt = problem.prior_rvs(1); print(tt)
	tt = theta_nominal
	ysample_nominal = [problem.eta(tt, dd) for _ in range(n)]
	uncertainty_prop_plots(ysample_nominal, xlabs=problem.y_names, saveFig='UP_exp_nominal' if savefig else '')
	
	#Also plot the y's generated by the joint distribution p(y|theta,d)p(theta)
	print("Experiments simulated from the joint distribution:",flush=True)
	uq_thetas = problem.prior_rvs(n)
	uq_ys = [problem.eta(theta, dd) for theta in uq_thetas]
	uncertainty_prop_plots(uq_ys, c='orchid', xlabs=problem.y_names, saveFig='UP_joint_y0' if savefig else '')

#These cause problems on eofe8
#sensitivity analysis of the experiment models
def vv_SA_exp(problem, dd, p=8):
	#we want to see sensitivity of each yi to their inputs, theta and x
	#challenge: sobol_saltelli expects a function that takes a single list of parameters
	#right now, im doing this in a way that just deals with the thetas
	#i think i can handle including x's intelligently as well some day, using this filter:
	SA_filter = range(len(problem.theta_names)) #[]
		
	for i,yi in enumerate(problem.y_names):
		def exp_fn_i(param):
			y = problem.eta(param, dd) #want to figure out a smarter way to do analysis of x in the future
			yi = y[i]
			return yi

		expvar_names = problem.theta_names #+ problem.x_names
		expvar_dists = [prior[0] for prior in problem.priors] #+ [prior[0] for prior in problem.x_dists]
		expvar_bounds=[prior[1] for prior in problem.priors] #+ [prior[1] for prior in problem.x_dists]
			
		#so ugly!!!
		Si_1 = sobol_saltelli(exp_fn_i, 
							2**p, #SALib wants powers of 2 for convergence
							var_names=[x for i,x in enumerate(expvar_names) if i in SA_filter], 
							var_dists=[x for i,x in enumerate(expvar_dists) if i in SA_filter], 
							var_bounds=[x for i,x in enumerate(expvar_bounds) if i in SA_filter], 
							conf = 0.99, doSijCalc=False, doPlot=True, doPrint=True)	
							
def vv_SA_joint(problem, p=5):
	#it'll be straightforward to see the dependence of QoI on theta
	Si = sobol_saltelli(problem.H, 
						2**p, #SALib wants powers of 2 for convergence
						var_names=problem.theta_names, 
						var_dists=[prior[0] for prior in problem.priors], 
						var_bounds=[prior[1] for prior in problem.priors],  #need to do something odd here....?
						conf = 0.95, doSijCalc=False, doPlot=True, doPrint=True)

def vv_gbi_test(problem, d, N, y=[], ncomp=0):		
	print("Training...")
	theta_train = problem.prior_rvs(N)
	qoi_train = [problem.H(theta) for theta in theta_train]
	y_train = [problem.eta(theta, d) for theta in theta_train]
	
	gmm = gbi_train_model(theta_train, qoi_train, y_train, verbose=2, ncomp=ncomp)
	
	if y==[]:
		print("Determining random measurement Yd...")
		truth_theta = problem.prior_rvs(1)
		Yd = problem.eta(truth_theta, d)
	else:
		Yd = y
	
	print("Conditioning...")
	a,b,c = gbi_condition_model(gmm, Yd, verbose=2)
	
	if y==[]:
		plot_predictive_posterior(a, b, c, 0, 500, drawplot=False, plotmean=True)
		plt.axvline(problem.H(truth_theta), c='blue')
		plt.show()
	else:
		plot_predictive_posterior(a, b, c, 0, 500, drawplot=True)

def vv_obed_gbi(problem, d, n_mc=10**4, n_gmm=10**4):
	U, U_list = U_varH_gbi(d, problem, n_mc=n_mc, n_gmm=n_gmm, doPrint=True)
	print(U)
	#print(U_list)
	uncertainty_prop_plot(U_list, c='royalblue', xlab="specific U")#, saveFig='OBEDresult')
	return U
	
def uncertainty_mc(problem, dd, dname, n_mc=10**2, n_gmm=10**2, n_test=10**2):
	theta_check = problem.prior_rvs(n_gmm)
	ncomp = find_ncomp( theta_check, 
						[problem.H(theta) for theta in theta_check], 
						[problem.eta(theta, dd) for theta in theta_check])
	print("Using ncomp =",ncomp)
	
	util_samples=[]
	for ii in range(n_test):
		util, _ = U_varH_gbi(dd, problem, n_mc=n_mc, n_gmm=n_gmm, ncomp=ncomp, doPrint=False)
		util_samples.append(util)
		print(ii, util, flush=True)
		
	uncertainty_prop_plot(util_samples, c='purple', xlab="utility for d="+dname)
	print("variance of utility estimation for n_mc="+str(n_mc)+", n_gmm"+str(n_gmm),"is",statistics.variance(util_samples))
	return util_samples

if __name__ == '__main__':  
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--run', metavar='string', required=True, help='Functions to run for this vvopt analysis')
	args = parser.parse_args()
	
	###Problem Definition
	alphas = [1,1,1,10,10,10,100,100,100] #prior mean of masses
	betas = [.1,1,10,.1,1,10,.1,1,10] #prior variance of masses
	problem = simple_mass_problem_def(alphas, betas)
	
	d_best = [0.001]*len(alphas)
	d_worst = [10]*len(alphas)
	d_example = [0.5]*len(alphas)
	
	req = 340
	theta_nominal = alphas
	y_nominal = problem.eta(theta_nominal, d_example, err=False)

	###Uncertainty Quantification
	if args.run == "nominal":
		vv_nominal(problem, req, theta_nominal, y_nominal)
	
	if args.run == "UP_QoI":
		vv_UP_QoI(problem, req, n=10**5)
	
	if args.run == "SA_QoI":
		vv_SA_QoI(problem, p=8)
	
	if args.run == "UP_exp":
		vv_UP_exp(problem, d_example, theta_nominal, n=10**5)
	
	#This one is boring for this simple mass problem
	if args.run == "SA_exp":
		vv_SA_exp(problem, d_example)

	###Optimal Bayesian Experimental Design
	if args.run == "gbi_test":
		vv_gbi_test(problem, d_example, 10**2, y_nominal, ncomp=1)
	if args.run == "gbi_test_rand":
		vv_gbi_test(problem, d_example, 10**2, ncomp=10)
	
	#d_example is 2.2833586292733474
	if args.run == "obed_gbi":
		U_hist = vv_obed_gbi(problem, d_example, 10**2, 10**2)
	
	#this testing shows that for n_mc=10**2, n_gmm=10**2,
	#the utility is estimated with a variance of _____
	#this precision will carry through to the optimization problem
	#(n_mc=10**4, n_gmm=10**4, looked like it had stddev 0.2
	if args.run == "uncertainty_mc":
		#util_samples = uncertainty_mc(problem, d_example, "d_example", n_mc=10**3, n_gmm=10**3, n_test=10**3)
		#util_samples = uncertainty_mc(problem, d_best, "d_best", n_mc=10**3, n_gmm=10**3, n_test=10**3)
		util_samples = uncertainty_mc(problem, d_worst, "d_worst", n_mc=10**3, n_gmm=10**3, n_test=10**3)
		print(util_samples)
	
	if args.run == "vv_opt_parallel":
		costs, utilities, designs = ngsa2_problem_parallel(8, problem, hours=0, minutes=0, popSize=10, nMonteCarlo=10**3, nGMM=10**3)
		plot_ngsa2(costs, utilities, showPlot=True, savePlot=False, logPlotXY=[False,False])
	
