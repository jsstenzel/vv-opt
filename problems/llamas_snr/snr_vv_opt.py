import sys
import os
import scipy.stats
import math
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import csv
import dill

sys.path.append('../..')
#focal plane
from problems.gp_test.gp_test_problem import *
#analysis
from obed.obed_multivar import *
from obed.obed_gbi import *
from obed.pdf_estimation import *
from uq.uncertainty_propagation import *
#from uq.sensitivity_analysis import *
from opt.ngsa import *

################################
#Useful definitions
################################


################################
#Analysis functions
################################

def vv_nominal(problem, req, theta_nominal, y_nominal):
	print("QoI requirement:", req)
	QoI_nominal = problem.H(theta_nominal)
	print("Given the nominal theta:", theta_nominal)
	print("Nominal y:", y_nominal)
	print("Nominal QoI:", QoI_nominal)


###uncertainty analysis
def vv_UP_QoI(problem, req):
	#uncertainty propagation of HLVA
	uq_thetas = problem.prior_rvs(1000)
	Qs = [problem.H(theta) for theta in uq_thetas]
	#uncertainty_prop_plot([theta[0] for theta in uq_thetas], xlab="How to plot this...")
	uncertainty_prop_plot(Qs, xlab="QoI: Avg. Throughput", vline=[req])

	#prob of meeting req along priors:
	count_meetreq = 0
	for Q in Qs:
		if Q <= req:
			count_meetreq += 1
	prob_meetreq = count_meetreq / len(Qs)
	print("Probability of meeting requirement given priors:", prob_meetreq)

"""
#sensitivity analysis of HLVA
def vv_SA_QoI():
	#it'll be straightforward to see the dependence of QoI on theta
	Si = sobol_saltelli(problem.H, 
						2**5, #SALib wants powers of 2 for convergence
						var_names=problem.theta_names, 
						var_dists=[prior[0] for prior in problem.priors], 
						var_bounds=[prior[1] for prior in problem.priors], 
						conf = 0.95, doSijCalc=False, doPlot=True, doPrint=True)
"""

#Uncertainty analysis of the experiment models
def vv_UP_exp(problem, dd, savefig=False):
	print("Likelihood distribution for nominal historical case:",flush=True)
	tt = problem.prior_rvs(1); print(tt)
	ysample_nominal = [problem.eta(tt, dd) for _ in range(1000)]
	uncertainty_prop_plots(ysample_nominal, xlabs=["Y0","Y1","Y2"], saveFig='UP_exp_nominal' if savefig else '')
	
	#Also plot the y's generated by the joint distribution p(y|theta,d)p(theta)
	print("Experiments simulated from the joint distribution:",flush=True)
	uq_thetas = problem.prior_rvs(1000)
	uq_ys = [problem.eta(theta, dd) for theta in uq_thetas]
	uncertainty_prop_plots(uq_ys, c='orchid', saveFig='UP_joint_y0' if savefig else '')

#"""	These cause problems on eofe8
#sensitivity analysis of the experiment models
def vv_SA_exp(problem, dd):
		#we want to see sensitivity of each yi to their inputs, theta and x
		#instead of trying to break eta into its constitutent experiments, i think i want to just use all of eta,
		#and doing separate sensitivity analysis on each of the y[i] coming from theta, over entire x and theta span
		#sobol_saltelli expects a function that takes a single list of parameters
		def eta_1(param): #gain
			gain = param[0]
			rn = param[1]
			dc = param[2]
			_x = dict(zip(problem.x_names, problem.x_default)) 
			_x["sigma_dc"] = param[3]
			_x["P_signal"] = param[4]
			_x["P_noise"] = param[5]
			_x["T_ccd"] = param[6]
			_x["sigma_E"] = param[7]
			_x["w"] = param[8]
			_x["activity_cd109"] = param[9]
			y = gain_exp(gain, rn, dc, dd[0], dd[1], _x, err=True)
			return y
		def eta_2(param): #rn
			gain = param[0]
			rn = param[1]
			_x = dict(zip(problem.x_names, problem.x_default)) 
			_x["sigma_stray"] = param[2]
			_x["sigma_dc"] = param[3]
			y = read_noise_exp(gain, rn, dd[2], _x, err=True)
			return y
		def eta_3(param): #dc
			gain = param[0]
			rn = param[1]
			dc = param[2]
			_x = dict(zip(problem.x_names, problem.x_default)) 
			_x["sigma_stray"] = param[3]
			_x["sigma_dc"] = param[4]
			y = dark_current_exp(gain, rn, dc, dd[3], dd[4], dd[5], _x, err=True)
			return y
		#use partials to define these later?

		expvar_names = problem.theta_names + problem.x_names
		expvar_dists = [prior[0] for prior in problem.priors] + [prior[0] for prior in problem.x_dists]
		expvar_bounds=[prior[1] for prior in problem.priors] + [prior[1] for prior in problem.x_dists]
			
		#so ugly!!!
		Si_1 = sobol_saltelli(eta_1, 
							2**8, #SALib wants powers of 2 for convergence
							var_names=[x for i,x in enumerate(expvar_names) if i in [0,1,2,5,8,9,10,12,13,14]], 
							var_dists=[x for i,x in enumerate(expvar_dists) if i in [0,1,2,5,8,9,10,12,13,14]], 
							var_bounds=[x for i,x in enumerate(expvar_bounds) if i in [0,1,2,5,8,9,10,12,13,14]], 
							conf = 0.99, doSijCalc=False, doPlot=True, doPrint=True)
		
		Si_2 = sobol_saltelli(eta_2, 
							2**8, #SALib wants powers of 2 for convergence
							var_names=[x for i,x in enumerate(expvar_names) if i in [0,1,5,7]], 
							var_dists=[x for i,x in enumerate(expvar_dists) if i in [0,1,5,7]], 
							var_bounds=[x for i,x in enumerate(expvar_bounds) if i in [0,1,5,7]], 
							conf = 0.99, doSijCalc=False, doPlot=True, doPrint=True)
		
		Si_3 = sobol_saltelli(eta_3, 
							2**8, #SALib wants powers of 2 for convergence
							var_names=[x for i,x in enumerate(expvar_names) if i in [0,1,2,5,7]], 
							var_dists=[x for i,x in enumerate(expvar_dists) if i in [0,1,2,5,7]], 
							var_bounds=[x for i,x in enumerate(expvar_bounds) if i in [0,1,2,5,7]], 
							conf = 0.99, doSijCalc=False, doPlot=True, doPrint=True)	
#"""						

def vv_gbi_test(problem, d, N, Yd=[], ncomp=0):		
	print("Training...")
	theta_train = problem.prior_rvs(N)
	qoi_train = [problem.H(theta) for theta in theta_train]
	y_train = [problem.eta(theta, d) for theta in theta_train]
	
	gmm = gbi_train_model(theta_train, qoi_train, y_train, verbose=2, ncomp=ncomp)
	
	if Yd==[]:
		print("Determining random measurement Yd...")
		truth_theta = problem.prior_rvs(1)
		Yd = problem.eta(truth_theta, d)
	
	print("Conditioning...")
	a,b,c = gbi_condition_model(gmm, Yd, verbose=2)
	
	if Yd==[]:
		plot_predictive_posterior(a, b, c, 0, 7, drawplot=True)
	else:
		plot_predictive_posterior(a, b, c, 0, 7, drawplot=False, plotmean=True)
		plt.axvline(problem.H(truth_theta), c='blue')
		plt.show()

def vv_obed_gbi(problem, d):
	U, U_list = U_varH_gbi(d, problem, n_mc=10**3, n_gmm=10**3, doPrint=True)
	print(U)
	#print(U_list)
	uncertainty_prop_plot(U_list, c='royalblue', xlab="specific U")#, saveFig='OBEDresult')
	return U
	
def uncertainty_mc(problem):
	util_samples = []
	for ii in range(1000):
		print(ii, flush=True)
		util = U_varH_gbi(d_historical, fp, n_mc=5*10**3, n_gmm=10**3, ncomp=5, doPrint=False)
		util_samples.append(util)
		
	uncertainty_prop_plot(util_samples, c='purple', xlab="utility for d=d_hist")
	print(statistics.variance(util_samples))

if __name__ == '__main__':  
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--run', metavar='string', required=True, help='Functions to run for this vvopt analysis')
	args = parser.parse_args()
	
	###Problem Definition
	d_example = [3]#gp_test.sample_d(1)
	problem = update_gp_problem(gp_test, d_example)
	
	req = 0.65
	theta_nominal = [sample_gp_prior(.0001, 100000, vph_red_pts, prior_mean_vph_red)]
	y_nominal = problem.eta(theta_nominal, d_example, err=False)

	###Uncertainty Quantification
	if args.run == "nominal":
		vv_nominal(problem, req, theta_nominal, y_nominal)
	
	if args.run == "UP_QoI":
		vv_UP_QoI(problem, req)
	
	if args.run == "SA_QoI":
		vv_SA_QoI(problem)
	
	if args.run == "UP_exp":
		vv_UP_exp(problem, d_example)
	
	if args.run == "SA_exp":
		vv_SA_exp(problem, d_example)

	###Optimal Bayesian Experimental Design
	if args.run == "gbi_test":
		vv_gbi_test(problem, d_example, 10**1, ncomp=1)
	if args.run == "gbi_test_rand":
		vv_gbi_test(problem, d_example, 10**2, y_nominal, ncomp=1)
	
	if args.run == "obed_gbi":
		U_hist = vv_obed_gbi(problem, d_example)
	
	if args.run == "uncertainty_mc":
		uncertainty_mc(problem)
		
	#costs, utilities, designs = ngsa2_problem_parallel(8, problem, hours=0, minutes=0, popSize=12, nMonteCarlo=5*10**3, nGMM=5*10**3)
	#plot_ngsa2(costs, utilities, showPlot=True, savePlot=False, logPlotXY=[False,False])
	
